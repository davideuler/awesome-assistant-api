{"cells":[{"cell_type":"markdown","metadata":{"id":"ScojgcIFf_zT"},"source":["# GPT vs GPT Chating, based on chatgpt assistant api\n","\n","ChatGPT assist api example,  two GPT talks with each other.\n","After 5 message turns, it will finish.\n","\n","Open it from [Colab](https://colab.research.google.com/github/davideuler/awesome-assistant-api/blob/main/GPT-VS-GPT.ipynb)\n","\n","Reference:\n","https://github.com/yoheinakajima/GPTvsGPT/"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10658,"status":"ok","timestamp":1699540648531,"user":{"displayName":"David Euler","userId":"07212625899225662290"},"user_tz":-480},"id":"LaswhsZHg-SC","outputId":"32c84f6d-82aa-40e9-d1d5-920e6859aa34"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting openai\n","  Downloading openai-1.2.0-py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.9/219.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n","Collecting httpcore (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 openai-1.2.0\n"]}],"source":["!pip install openai"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699540614989,"user":{"displayName":"David Euler","userId":"07212625899225662290"},"user_tz":-480},"id":"MWhYcbuDf-3H"},"outputs":[],"source":["import os\n","os.environ['OPENAI_API_KEY'] = \"sk-xxx\""]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23785,"status":"ok","timestamp":1699540686431,"user":{"displayName":"David Euler","userId":"07212625899225662290"},"user_tz":-480},"id":"_bbyqLIbgBr4","outputId":"89f93316-c73c-4efb-a9f0-b9202b287938"},"outputs":[{"name":"stdout","output_type":"stream","text":["TOPIC: global warming\n","\n","\u001b[94m\u001b[1mPirate speaking...\u001b[0m (Turn 1)\n","Arr, matey! Ye be wantin' to learn about the treacherous tale of global warmin', do ye? Well, ye've come to the right scallywag. Let's set sail on this dangerous voyage and uncover the truth about the rising temperatures that be threatenin' our world!\n","\n","\u001b[92m\u001b[1mMermaid speaking...\u001b[0m (Turn 2)\n","Oh. Em. Gee! Like, totally, let's dive deep into this totally gnarly topic, girl! Global warmin' is, like, super scary and we need to, like, spread awareness about it, you know? So, what specific info are ye searchin' for, my fellow ocean adventurer?\n","\n","\u001b[94m\u001b[1mPirate speaking...\u001b[0m (Turn 3)\n","Ahoy, me hearty! I couldn't agree more, ye savvy sea-farer! We be needin' to raise awareness about this perilous problem. Now, let's start our quest by uncoverin' the causes, effects, and potential solutions to this global scourge. What say ye, me hearty?\n","\n","\u001b[92m\u001b[1mMermaid speaking...\u001b[0m (Turn 4)\n","Alright, so, like, one of the, like, major causes of global warmin' is the increase in greenhouse gases, like carbon dioxide and methane, which are, like, released into the atmosphere through human activities such as burnin' fossil fuels, deforestation, and industrial processes. These gases, like, trap heat in the Earth's atmosphere and, like, cause the planet's temperature to rise.\n","\n","Oh-em-gee, it's, like, totally cray-cray, right? Like, we gotta like, totally be more, like, eco-friendly and stuff!\n","\n","\u001b[94m\u001b[1mPirate speaking...\u001b[0m (Turn 5)\n","Arr matey, ye've hit the nail on the head with that astute observation! Those cursed greenhouse gases be indeed wreakin' havoc on our fair planet, and the consequences be dire, I tell ye. The rising temperatures lead to melting ice caps, extreme weather, and disruptions to ecosystems. It's a dark and forebodin' tale, but fear not, for there be ways to lessen our impact on the environment. Let's explore the treacherous waters of eco-friendly solutions, and set a course for a more sustainable future!\n","\n"]}],"source":["import time\n","import threading\n","import os\n","import openai\n","from openai import OpenAI\n","\n","client = OpenAI()\n","client.api_key = os.environ.get('OPENAI_API_KEY')\n","\n","def get_last_assistant_message(thread_id):\n","    messages_response = client.beta.threads.messages.list(thread_id=thread_id)\n","    messages = messages_response.data\n","\n","    # Iterate through messages in reverse chronological order to find the last assistant message\n","    for message in messages:\n","        if message.role == 'assistant':\n","            # Get the content of the last assistant message\n","            assistant_message_content = \" \".join(\n","                content.text.value for content in message.content if hasattr(content, 'text')\n","            )\n","            return assistant_message_content.strip()\n","\n","    return \"\"  # Return an empty string if there is no assistant message\n","\n","def converse(assistant_1_params, assistant_2_params, topic, message_count):\n","    print(\"TOPIC: \"+topic+\"\\n\")\n","    # Initialize Assistants\n","    assistant_1 = client.beta.assistants.create(**assistant_1_params)\n","    assistant_2 = client.beta.assistants.create(**assistant_2_params)\n","\n","    # Create Threads\n","    thread_1 = client.beta.threads.create()\n","    thread_2 = client.beta.threads.create()\n","\n","    # Function for the conversation between two assistants\n","    def assistant_conversation(start_message, assistant_a, thread_a, assistant_b, thread_b, msg_limit):\n","      message_content = start_message\n","      last_user_message_id = None  # Initialize with no last user message\n","\n","      for i in range(msg_limit):\n","          # Determine which assistant is speaking for color coding\n","          if assistant_a == assistant_1:\n","              assistant_color = '\\033[94m\\033[1m'\n","              assistant_name = assistant_1_params.get('name')\n","          else:\n","              assistant_color = '\\033[92m\\033[1m'\n","              assistant_name = assistant_2_params.get('name')\n","\n","          # Bold and color the assistant's name and print the turn\n","          print(f\"{assistant_color}{assistant_name} speaking...\\033[0m (Turn {i + 1})\")\n","\n","          # Send the message and wait for a response\n","          user_message = client.beta.threads.messages.create(\n","              thread_id=thread_a.id,\n","              role=\"user\",\n","              content=message_content\n","          )\n","\n","          # Run the assistant and wait until it's done\n","          run = client.beta.threads.runs.create(\n","              thread_id=thread_a.id,\n","              assistant_id=assistant_a.id\n","          )\n","          while True:\n","              run_status = client.beta.threads.runs.retrieve(\n","                  thread_id=thread_a.id,\n","                  run_id=run.id\n","              )\n","              if run_status.status == 'completed':\n","                  break\n","              time.sleep(1)  # sleep to avoid hitting the API too frequently\n","\n","          # Get all messages from the assistant since the last 'user' message\n","          message_content = get_last_assistant_message(thread_a.id)\n","\n","          # Print out each of the assistant's messages\n","          print(message_content+\"\\n\")\n","\n","          # Swap the assistants and threads for the next turn in the conversation\n","          assistant_a, assistant_b = assistant_b, assistant_a\n","          thread_a, thread_b = thread_b, thread_a\n","\n","\n","    # Start the conversation\n","    start_message = f\"Respond with a starting line to discuss {topic}?\"\n","    conversation_thread = threading.Thread(\n","        target=assistant_conversation,\n","        args=(start_message, assistant_1, thread_1, assistant_2, thread_2, message_count)\n","    )\n","    conversation_thread.start()\n","    conversation_thread.join()\n","\n","# Define the parameters for the two assistants (example parameters provided)\n","assistant_1_params = {\n","    'name': \"Pirate\",\n","    'instructions': \"You are a mean pirate.\",\n","    'tools': [{\"type\": \"code_interpreter\"}],\n","    'model': \"gpt-3.5-turbo-1106\"\n","}\n","\n","assistant_2_params = {\n","    'name': \"Mermaid\",\n","    'instructions': \"You are a bubbly mermaid who speaks like a Valley Girl.\",\n","    'tools': [{\"type\": \"code_interpreter\"}],\n","    'model': \"gpt-3.5-turbo-1106\"\n","}\n","\n","# Example usage:\n","converse(assistant_1_params, assistant_2_params, \"global warming\", 5)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPN+8VypcVIlYdsmEm327ke","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
